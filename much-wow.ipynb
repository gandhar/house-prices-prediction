{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p,inv_boxcox\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "sns.set()\n",
    "\n",
    "def log_transform(df,col_name):\n",
    "    df[col_name+'_Log'] = np.log(df[col_name])\n",
    "    \n",
    "    print(\"Skewness_orig: %f\" % df[col_name].skew())\n",
    "    print(\"Kurtosis_orig: %f\" % df[col_name].kurt())\n",
    "    print(\"Skewness_new: %f\" % df[col_name+'_Log'].skew())\n",
    "    print(\"Kurtosis_new: %f\" % df[col_name+'_Log'].kurt())\n",
    "\n",
    "    f, axes = plt.subplots(2, 1)\n",
    "    f.tight_layout()\n",
    "    sns.distplot(df[col_name], ax=axes[0])\n",
    "    sns.distplot(df[col_name+'_Log'], ax=axes[1])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def add_sqrt_transform(df,col_name,add):\n",
    "    df[col_name+'_sqrt'] = np.sqrt(df[col_name]+add)\n",
    "    \n",
    "    print(\"Skewness_orig: %f\" % df[col_name].skew())\n",
    "    print(\"Kurtosis_orig: %f\" % df[col_name].kurt())\n",
    "    print(\"Skewness_new: %f\" % df[col_name+'_sqrt'].skew())\n",
    "    print(\"Kurtosis_new: %f\" % df[col_name+'_sqrt'].kurt())\n",
    "\n",
    "    f, axes = plt.subplots(2, 1)\n",
    "    f.tight_layout()\n",
    "    sns.distplot(df[col_name], ax=axes[0])\n",
    "    sns.distplot(df[col_name+'_sqrt'], ax=axes[1])\n",
    "    plt.show()\n",
    "    \n",
    "def print_missing_data(df,top=20):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print(missing_data.head(top))\n",
    "    \n",
    "def get_corr_pairs(df):\n",
    "    corrs = df.corr() >= 0.8\n",
    "    names = list(corrs.index)\n",
    "    corr_pairs={}\n",
    "    for item in sorted(corrs):\n",
    "        relevant=[ names[ind] for ind, row in enumerate(corrs[item]) if row and names[ind] != item ]\n",
    "        if len(relevant)>0:\n",
    "            corr_pairs[item] = relevant\n",
    "    return corr_pairs\n",
    "    \n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def prediction_stats(y_test,y_pred):\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Mean Absolute Percentage Error:',mean_absolute_percentage_error(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 82) (1459, 82) (2919, 82)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/Users/gandharkamat/projects/8010/Final/train.csv\")\n",
    "df_test_data = pd.read_csv(\"/Users/gandharkamat/projects/8010/Final/test.csv\")\n",
    "sals_price=pd.read_csv(\"/Users/gandharkamat/projects/8010/Final/test_actual_price.csv\")\n",
    "\n",
    "df_test = pd.merge(df_test_data, sals_price,  how='inner', on='Id')\n",
    "\n",
    "df_train['source']='train'\n",
    "df_test['source']='test'\n",
    "df = pd.concat([df_train,df_test], ignore_index = True, sort = False)\n",
    "\n",
    "print(df_train.shape, df_test.shape, df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1         60       RL         65.0     8450   Pave  None      Reg   \n",
       "1   2         20       RL         80.0     9600   Pave  None      Reg   \n",
       "2   3         60       RL         68.0    11250   Pave  None      IR1   \n",
       "3   4         70       RL         60.0     9550   Pave  None      IR1   \n",
       "4   5         60       RL         84.0    14260   Pave  None      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolQC Fence MiscFeature MiscVal MoSold YrSold  \\\n",
       "0         Lvl    AllPub  ...   None  None        None       0      2   2008   \n",
       "1         Lvl    AllPub  ...   None  None        None       0      5   2007   \n",
       "2         Lvl    AllPub  ...   None  None        None       0      9   2008   \n",
       "3         Lvl    AllPub  ...   None  None        None       0      2   2006   \n",
       "4         Lvl    AllPub  ...   None  None        None       0     12   2008   \n",
       "\n",
       "  SaleType  SaleCondition  SalePrice  source  \n",
       "0       WD         Normal     208500   train  \n",
       "1       WD         Normal     181500   train  \n",
       "2       WD         Normal     223500   train  \n",
       "3       WD        Abnorml     140000   train  \n",
       "4       WD         Normal     250000   train  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSSubClass'] = df['MSSubClass'].apply(str)\n",
    "df['YrSold'] = df['YrSold'].astype(str)\n",
    "df['MoSold'] = df['MoSold'].astype(str)\n",
    "df['Functional'] = df['Functional'].fillna('Typ') \n",
    "df['Electrical'] = df['Electrical'].fillna(\"SBrkr\") \n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(\"TA\") \n",
    "df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0]) \n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n",
    "\n",
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    df[col] = df[col].fillna('None')\n",
    "\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    df[col] = df[col].fillna('None')\n",
    "\n",
    "df['MSZoning'] = df.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "objects = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == object:\n",
    "        objects.append(i)\n",
    "df.update(df[objects].fillna('None'))\n",
    "\n",
    "df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "df.update(df[numerics].fillna(0))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gandharkamat/projects/venv/lib/python3.7/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = df.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "df['YrBltAndRemod']=df['YearBuilt']+df['YearRemodAdd']\n",
    "df['TotalSF']=df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "df['Total_sqr_footage'] = (df['BsmtFinSF1'] + df['BsmtFinSF2'] +\n",
    "                                 df['1stFlrSF'] + df['2ndFlrSF'])\n",
    "\n",
    "df['Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) +\n",
    "                               df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))\n",
    "\n",
    "df['Total_porch_sf'] = (df['OpenPorchSF'] + df['3SsnPorch'] +\n",
    "                              df['EnclosedPorch'] + df['ScreenPorch'] +\n",
    "                              df['WoodDeckSF'])\n",
    "\n",
    "df['haspool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['has2ndfloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasgarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasbsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "df['hasfireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "df.drop(df[(df['source'] == 'train') & (df['GrLivArea']>5000)].index,inplace=True)\n",
    "df.drop(df[(df['source'] == 'train') & (df['LotArea']>50000)].index,inplace=True)\n",
    "df.drop(df[(df['source'] == 'train') & (df['LotFrontage']>250)].index,inplace=True)\n",
    "\n",
    "df.shape\n",
    "\n",
    "numerics2 = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_df = df[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_df[skew_df > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "# y = np.log(df[df['source'] == 'train']['SalePrice'])\n",
    "# y_test = np.log(df[df['source'] == 'test']['SalePrice'])\n",
    "\n",
    "for i in skew_index:\n",
    "    df[i] = boxcox1p(df[i], boxcox_normmax(df[i] + 1))\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "\n",
    "\n",
    "final_df = pd.get_dummies(df).reset_index(drop=True)\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# final_df = pd.DataFrame(scaler.fit_transform(final_df_1), index=final_df_1.index, columns=final_df_1.columns)\n",
    "# # final_df\n",
    "\n",
    "# final_df['Id'] = df['Id']\n",
    "# final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 337)\n",
      "(1448, 332) (1448,) (1459, 332) (1459,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1448    15.465436\n",
       "1449    16.336388\n",
       "1450    16.513605\n",
       "1451    16.565789\n",
       "1452    16.528663\n",
       "          ...    \n",
       "2902    15.207205\n",
       "2903    14.789481\n",
       "2904    15.853303\n",
       "2905    15.866708\n",
       "2906    16.495567\n",
       "Name: SalePrice, Length: 1459, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "X = final_df[final_df['source_train'] == 1]\n",
    "y = X['SalePrice']\n",
    "X.drop('SalePrice',axis=1,inplace=True)\n",
    "X.drop('Id',axis=1,inplace=True)\n",
    "\n",
    "# print(final_df_1[final_df_1['source_test'] == 1])\n",
    "\n",
    "X_test = final_df[final_df['source_train'] == 0]\n",
    "print(X_test.shape)\n",
    "y_test = X_test['SalePrice']\n",
    "X_test.drop('SalePrice',axis=1,inplace=True)\n",
    "X_test.drop('Id',axis=1,inplace=True)\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "X_test = X_test.drop(overfit, axis=1)\n",
    "\n",
    "print(X.shape, y.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# outliers = [30, 88, 462, 631, 1322]\n",
    "# X = train_df.drop(X.index[outliers])\n",
    "# y = train_df.drop(y.index[outliers])\n",
    "\n",
    "# overfit = []\n",
    "# for i in X.columns:\n",
    "#     counts = X[i].value_counts()\n",
    "#     zeros = counts.iloc[0]\n",
    "#     if zeros / len(X) * 100 > 99.94:\n",
    "#         overfit.append(i)\n",
    "\n",
    "# overfit = list(overfit)\n",
    "# X = X.drop(overfit, axis=1)\n",
    "# X_sub = X_sub.drop(overfit, axis=1)\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 20, 'epsilon': 0.008, 'gamma': 0.0003}\n",
      "-0.30099683773066505\n",
      "Mean Absolute Error: 6077166.368282289\n",
      "Mean Squared Error: 166165570131699.1\n",
      "Root Mean Squared Error: 12890522.492579542\n",
      "Mean Absolute Percentage Error: 48.35050807140407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def svr_thing():\n",
    "    svr = SVR()\n",
    "    parameters = {\n",
    "        'C':[20 ], 'epsilon' : [0.008], 'gamma': [0.0003]\n",
    "                 }\n",
    "        \n",
    "    svr_regressor = GridSearchCV(svr, parameters, scoring = 'neg_mean_squared_error', cv=5,n_jobs=-1,verbose=2)\n",
    "    svr_regressor.fit(X,y)\n",
    "    \n",
    "    print(svr_regressor.best_params_)\n",
    "    print(svr_regressor.best_score_)\n",
    "\n",
    "    y_pred = svr_regressor.predict(X_test)\n",
    "\n",
    "    prediction_stats(np.expm1(y_test),np.expm1(y_pred))\n",
    "    output_all['svr'] = np.expm1(y_pred)\n",
    "\n",
    "svr_thing()\n",
    "# output_all\n",
    "\n",
    "# SVR()\n",
    "# svr_model_full_data = svr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 408 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1220 tasks      | elapsed:    6.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0, 'fit_intercept': True, 'normalize': False}\n",
      "-0.01416407272898457\n",
      "Mean Absolute Error: 13378.249460001012\n",
      "Mean Squared Error: 569323043.1326401\n",
      "Root Mean Squared Error: 23860.49125924779\n",
      "Mean Absolute Percentage Error: 8.173035439232242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>11.561716</td>\n",
       "      <td>11.693216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1461</td>\n",
       "      <td>12.055250</td>\n",
       "      <td>11.969641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1462</td>\n",
       "      <td>12.154253</td>\n",
       "      <td>12.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1463</td>\n",
       "      <td>12.183316</td>\n",
       "      <td>12.213653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>12.162643</td>\n",
       "      <td>12.178081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2914</td>\n",
       "      <td>11.413105</td>\n",
       "      <td>11.362736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2915</td>\n",
       "      <td>11.170435</td>\n",
       "      <td>11.287837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2916</td>\n",
       "      <td>11.782953</td>\n",
       "      <td>12.054027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2917</td>\n",
       "      <td>11.790557</td>\n",
       "      <td>11.669669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2918</td>\n",
       "      <td>12.144197</td>\n",
       "      <td>12.294168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual      ridge\n",
       "1460  11.561716  11.693216\n",
       "1461  12.055250  11.969641\n",
       "1462  12.154253  12.123119\n",
       "1463  12.183316  12.213653\n",
       "1464  12.162643  12.178081\n",
       "...         ...        ...\n",
       "2914  11.413105  11.362736\n",
       "2915  11.170435  11.287837\n",
       "2916  11.782953  12.054027\n",
       "2917  11.790557  11.669669\n",
       "2918  12.144197  12.294168\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "output_all = pd.DataFrame()\n",
    "output_all['actual'] = y_test\n",
    "\n",
    "def ridge_thing():\n",
    "    ridge = Ridge()\n",
    "    parameters = {'alpha': [ 0.1 + 0.1*i for i in range(100)],\n",
    "                 'fit_intercept':[True,False],\n",
    "                 'normalize': [True,False]\n",
    "                 }\n",
    "        \n",
    "    ridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_error', cv=5,n_jobs=-1,verbose=2)\n",
    "    ridge_regressor.fit(X,y)\n",
    "    \n",
    "    print(ridge_regressor.best_params_)\n",
    "    print(ridge_regressor.best_score_)\n",
    "\n",
    "    y_pred = ridge_regressor.predict(X_test)\n",
    "\n",
    "    prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "    output_all['ridge'] = y_pred\n",
    "\n",
    "ridge_thing()\n",
    "output_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0008, 'fit_intercept': True, 'normalize': False}\n",
      "-0.013517991235689527\n",
      "Mean Absolute Error: 13371.133431211361\n",
      "Mean Squared Error: 614044536.8507667\n",
      "Root Mean Squared Error: 24779.922050942103\n",
      "Mean Absolute Percentage Error: 8.150958545233527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    8.4s finished\n",
      "/Users/gandharkamat/projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "\n",
    "def lasso_thing():\n",
    "    lasso = Lasso() # 1\n",
    "    parameters = {'alpha': [1e-4,2e-4,4e-4,8e-4,1e-3,1e-2,1],\n",
    "                 'fit_intercept':[True,False],\n",
    "                 'normalize': [True,False]}\n",
    "    \n",
    "    lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv=5,n_jobs=-1,verbose=2)\n",
    "    lasso_regressor.fit(X,y) # 2\n",
    "    \n",
    "    print(lasso_regressor.best_params_)\n",
    "    print(lasso_regressor.best_score_)\n",
    "\n",
    "    y_pred = lasso_regressor.predict(X_test) # 3\n",
    "\n",
    "    prediction_stats(np.exp(y_test),np.exp(y_pred)) # 4 \n",
    "    output_all['lasso'] = np.exp(y_pred)\n",
    "\n",
    "lasso_thing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 602 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=6, max_features='auto',\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "Mean Absolute Error: 21769.624129466363\n",
      "Mean Squared Error: 1036904849.011683\n",
      "Root Mean Squared Error: 32201.00695648636\n",
      "Mean Absolute Percentage Error: 13.351049246396594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:    4.2s finished\n",
      "/Users/gandharkamat/projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\"max_depth\": range(2,10,2),\n",
    "              'min_samples_split': [2,5,8,10],\n",
    "            \"max_features\": [1, 3, 10, 50, 100, 'sqrt', 'auto','log2']}\n",
    "\n",
    "regressor_dtree = DecisionTreeRegressor()\n",
    "dtree=GridSearchCV(regressor_dtree,param_grid,cv=5,n_jobs=-1,verbose=2)\n",
    "dtree.fit(X,y)\n",
    "print(dtree.best_estimator_)\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "output_all['dtree'] = np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   51.7s remaining:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-ee74cc69de31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/venv/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfp = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\"max_depth\": range(6,12,2),\n",
    "              \"n_estimators\": [1500],\n",
    "            \"max_features\": ['auto'],\n",
    "             \"bootstrap\": [True]}\n",
    "\n",
    "rf = GridSearchCV(rfp, param_grid=param_grid,cv=5,n_jobs=-1,verbose=2)\n",
    "rf.fit(X, y)\n",
    "print(rf.best_estimator_)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "output_all['rf'] = np.exp(y_pred)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [4],\n",
    "    \"n_estimators\": [410],\n",
    "    'objective':['reg:squarederror']\n",
    "    }\n",
    "\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "\n",
    "xgbr=GridSearchCV(model_xgb,param_grid,cv=5,n_jobs=-1,verbose=2)\n",
    "xgbr.fit(X,y)\n",
    "print(xgbr.best_estimator_)\n",
    "\n",
    "y_pred = xgbr.predict(X_test)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "output_all['xgb'] = np.exp(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbp = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\"max_depth\": range(1,5,1),\n",
    "              \"n_estimators\": range(470,510,10),\n",
    "            \"criterion\": ['friedman_mse','mse']\n",
    "             }\n",
    "\n",
    "gb = GridSearchCV(gbp, param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "gb.fit(X, y)\n",
    "print(gb.best_estimator_)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "output_all['gb'] = np.exp(y_pred)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear reg to find linear combination of individual\n",
    "from sklearn import linear_model\n",
    "\n",
    "X_final = output_all.loc[:,['lasso','ridge','xgb','dtree','rf','gb']]\n",
    "X_final\n",
    "Y_final = output_all['actual']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_final, Y_final)\n",
    "\n",
    "print(regr.coef_,regr.intercept_)\n",
    "\n",
    "output_all['lr'] = regr.intercept_ +  \\\n",
    "    regr.coef_[0]*output_all['lasso']+ \\\n",
    "    regr.coef_[1]*output_all['ridge']+ \\\n",
    "    regr.coef_[2]*output_all['xgb']+ \\\n",
    "    regr.coef_[3]*output_all['dtree']+ \\\n",
    "    regr.coef_[4]*output_all['rf'] + \\\n",
    "    regr.coef_[5]*output_all['gb']\n",
    "\n",
    "output_all['lr']\n",
    "\n",
    "print(output_all['actual'],output_all['lr'])\n",
    "prediction_stats(output_all['actual'],output_all['lr'])\n",
    "\n",
    "output_all['guess'] = 0.1*output_all['xgb'] + 0.4*output_all['dtree']  + 0.3*output_all['rf'] + 0.2*output_all['gb']\n",
    "prediction_stats(output_all['actual'],output_all['guess'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='GrLivArea'\n",
    "log_transform(df,col)\n",
    "num_feats.remove(col)\n",
    "num_feats.append(col+'_Log')\n",
    "\n",
    "\n",
    "scale_variables = ['LotFrontage', 'LotArea_Log', 'YearBuilt', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea_Log', 'GarageYrBlt', 'GarageArea', 'PoolArea']\n",
    "\n",
    "robust = RobustScaler()\n",
    "df[scale_variables] = robust.fit_transform(df[scale_variables])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dummies \n",
    "df_dummies = pd.concat([df.loc[:,'source'],df.loc[:,num_feats],pd.get_dummies(df.loc[:,cat_feats])],axis=1)\n",
    "\n",
    "#prep for models \n",
    "train = df_dummies.loc[df_dummies['source']==\"train\"]\n",
    "test = df_dummies.loc[df_dummies['source']==\"test\"]\n",
    "\n",
    "train.drop(['source'],axis=1,inplace=True)\n",
    "test.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "target = 'SalePrice_Log'\n",
    "X = train.drop(target,axis=1)\n",
    "y = train[target]\n",
    "\n",
    "X_test = test.drop(target,axis=1)\n",
    "y_test = test[target]\n",
    "print(X.shape,y.shape,X_test.shape,y_test.shape)\n",
    "output_all = pd.DataFrame()\n",
    "output_all['actual'] = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "\n",
    "def lasso_thing():\n",
    "    lasso = Lasso()\n",
    "    parameters = {'alpha': [1e-4,2e-4,4e-4,8e-4,1e-3,1e-2,1],\n",
    "                 'fit_intercept':[True,False],\n",
    "                 'normalize': [True,False]}\n",
    "    \n",
    "    lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_log_error', cv=5,n_jobs=-1,verbose=2)\n",
    "    lasso_regressor.fit(X,y)\n",
    "    \n",
    "    print(lasso_regressor.best_params_)\n",
    "    print(lasso_regressor.best_score_)\n",
    "\n",
    "    y_pred = lasso_regressor.predict(X_test)\n",
    "\n",
    "    prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "    output_all['lasso'] = np.exp(y_pred)\n",
    "\n",
    "lasso_thing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def ridge_thing():\n",
    "    ridge = Ridge()\n",
    "    parameters = {'alpha': [ 10 + 0.01*i for i in range(500)],\n",
    "                 'fit_intercept':[True,False],\n",
    "                 'normalize': [True,False]\n",
    "                 }\n",
    "        \n",
    "    ridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_log_error', cv=5,n_jobs=-1,verbose=2)\n",
    "    ridge_regressor.fit(X,y)\n",
    "    \n",
    "    print(ridge_regressor.best_params_)\n",
    "    print(ridge_regressor.best_score_)\n",
    "\n",
    "    y_pred = ridge_regressor.predict(X_test)\n",
    "\n",
    "    prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "    output_all['ridge'] = np.exp(y_pred)\n",
    "\n",
    "ridge_thing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_log_error( np.exp(y_test),np.exp(y_pred) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "param_grid = {\"max_depth\": range(2,10,2),\n",
    "              'min_samples_split': [2,5,8,10],\n",
    "            \"max_features\": [1, 3, 10, 50, 100, 'sqrt', 'auto','log2']}\n",
    "\n",
    "regressor_dtree = DecisionTreeRegressor()\n",
    "dtree=GridSearchCV(regressor_dtree,param_grid,cv=5,n_jobs=-1,verbose=2)\n",
    "dtree.fit(X,y)\n",
    "print(dtree.best_estimator_)\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "output_all['dtree'] = np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfp = RandomForestRegressor()\n",
    "\n",
    "param_grid = {\"max_depth\": [17,19,21],\n",
    "              \"n_estimators\": [1500],\n",
    "            \"max_features\": ['auto'],\n",
    "             \"bootstrap\": [True]}\n",
    "\n",
    "rf = GridSearchCV(rfp, param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "rf.fit(X, y)\n",
    "print(rf.best_estimator_)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "output_all['rf'] = np.exp(y_pred)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbp = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\"max_depth\": range(1,5,1),\n",
    "              \"n_estimators\": range(470,510,10),\n",
    "            \"criterion\": ['friedman_mse','mse']\n",
    "             }\n",
    "\n",
    "gb = GridSearchCV(gbp, param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "gb.fit(X, y)\n",
    "print(gb.best_estimator_)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "output_all['gb'] = np.exp(y_pred)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": range(3,5,1),\n",
    "    \"n_estimators\": range(350,450,20),\n",
    "    'objective':['reg:squarederror']\n",
    "    }\n",
    "\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "\n",
    "xgbr=GridSearchCV(model_xgb,param_grid,cv=5,n_jobs=-1,verbose=2)\n",
    "xgbr.fit(X,y)\n",
    "print(xgbr.best_estimator_)\n",
    "\n",
    "y_pred = xgbr.predict(X_test)\n",
    "\n",
    "# model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "# model_xgb.fit(X, y)\n",
    "\n",
    "# y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "prediction_stats(np.exp(y_test),np.exp(y_pred))\n",
    "output_all['xgb'] = np.exp(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph multiple models \n",
    "output_all\n",
    "[ 10 + 0.01*i for i in range(500)]\n",
    "# sns.scatterplot(output_all['actual'],output_all['ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear reg to find linear combination of individual\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "X_final = output_all.loc[:,['lasso','ridge','xgb','dtree','rf','gb']] # here we have 2 variables for multiple regression. If you just want to use one variable for simple linear regression, then use X = df['Interest_Rate'] for example.Alternatively, you may add additional variables within the brackets\n",
    "Y_final = output_all['actual']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_final, Y_final)\n",
    "\n",
    "print(regr.coef_,regr.intercept_)\n",
    "\n",
    "output_all['lr'] = regr.intercept_ +  \\\n",
    "    regr.coef_[0]*output_all['lasso']+ \\\n",
    "    regr.coef_[1]*output_all['ridge']+ \\\n",
    "    regr.coef_[2]*output_all['xgb']+ \\\n",
    "    regr.coef_[3]*output_all['dtree']+ \\\n",
    "    regr.coef_[4]*output_all['rf'] + \\\n",
    "    regr.coef_[5]*output_all['gb']\n",
    "\n",
    "output_all['lr']\n",
    "\n",
    "print(output_all['actual'],output_all['lr'])\n",
    "prediction_stats(output_all['actual'],output_all['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_log_error( output_all['actual'],output_all['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
